import requests
import time
import random
from datetime import datetime, timedelta
import json
import argparse
from collections import defaultdict
import os
import glob

# ConfiguraciÃ³n de URLs (selecciÃ³n automÃ¡tica segÃºn entorno)
CACHE_URL = os.getenv('CACHE_URL', "http://cache:8001/eventos")
ALMACENAMIENTO_URL = os.getenv('ALMACENAMIENTO_URL', "http://almacenamiento:8000/eventos/getall_ids")

# ConfiguraciÃ³n de parÃ¡metros
MIN_IDS = int(os.getenv('MIN_IDS', 1))  # Usar 10000 en producciÃ³n
DURACION_DEFAULT = int(os.getenv('DURACION_MINUTOS', 0))  # 0=infinito

def limpiar_archivos_anteriores():
    """Elimina archivos JSON de estadÃ­sticas anteriores"""
    for f in glob.glob('estadisticas_*.json') + glob.glob('metricas_*.json'):
        try:
            os.remove(f)
            print(f"â™»ï¸ Eliminado archivo anterior: {f}")
        except Exception as e:
            print(f"âš ï¸ No se pudo eliminar {f}: {str(e)}")

def parse_args():
    """Analiza los argumentos de lÃ­nea de comandos con valor por defecto desde variables de entorno"""
    parser = argparse.ArgumentParser(description='Generador de trÃ¡fico para pruebas de cache')
    default_duration = int(os.getenv('DURACION_MINUTOS', '15'))  # Valor por defecto 15
    parser.add_argument('--duracion', 
                       type=int, 
                       default=default_duration,
                       help=f'DuraciÃ³n en minutos (default: {default_duration})')
    return parser.parse_args()


def esperar_ids_suficientes():
    """Espera hasta que haya al menos MIN_IDS disponibles"""
    print(f"\nğŸ” Buscando al menos {MIN_IDS} ID(s)...")
    while True:
        try:
            response = requests.get(ALMACENAMIENTO_URL, timeout=5)
            if response.status_code == 200:
                data = response.json()
                ids = data.get("ids", [])
                if len(ids) >= MIN_IDS:
                    print(f"âœ… IDs suficientes ({len(ids)}/{MIN_IDS}) encontrados")
                    return ids
                print(f"ğŸ”„ Esperando IDs... ({len(ids)}/{MIN_IDS})")
            else:
                print(f"âš ï¸ Error HTTP {response.status_code} al obtener IDs")
        except Exception as e:
            print(f"âŒ Error de conexiÃ³n: {str(e)}")
        time.sleep(5)

def generar_intervalo():
    """Genera un intervalo aleatorio entre consultas (0.1-1.0 segundos)"""
    return random.uniform(0.1, 1.0)

def guardar_metricas(estadisticas, metricas_ids):
    """Guarda todas las mÃ©tricas en archivos JSON con timestamp"""
    stats_dir = '/app/estadisticas'
    os.makedirs(stats_dir, exist_ok=True)
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    
    # Archivo de estadÃ­sticas generales
    archivo_estadisticas = f"{stats_dir}/estadisticas_generales_{timestamp}.json"
    with open(archivo_estadisticas, 'w') as f:
        json.dump(estadisticas, f, indent=2)
    print(f"ğŸ“Š EstadÃ­sticas generales guardadas en '{archivo_estadisticas}'")
    
    # Archivo de mÃ©tricas detalladas por ID
    archivo_metricas = f"{stats_dir}/metricas_ids_{timestamp}.json"

    with open(archivo_metricas, 'w') as f:
     json.dump({
        'ids_mas_consultados': sorted(
            [{
                'id': k, 
                'total': v,
                'cache_hits': metricas_ids['fuentes_por_id'][k]['CACHE'],
                'cache_misses': metricas_ids['fuentes_por_id'][k]['BACKEND'],
                'primer_uso': metricas_ids['timestamp_primer_uso'].get(k),
                'ultimo_uso': metricas_ids['timestamp_ultimo_uso'].get(k),
                'ratio_cache': metricas_ids['fuentes_por_id'][k]['CACHE'] / v if v > 0 else 0
            } for k, v in metricas_ids['conteo_por_id'].items()],
            key=lambda x: x['total'], reverse=True),
        'resumen': {
            'total_ids_unicos': len(metricas_ids['conteo_por_id']),
            'promedio_consultas_por_id': (
                estadisticas['total_consultas'] / len(metricas_ids['conteo_por_id']) 
                if metricas_ids['conteo_por_id'] else 0
            ),
            'tiempo_ejecucion_minutos': estadisticas['config']['duracion_minutos'],
            'cache_hit_global': (
                estadisticas['cache_hits'] / estadisticas['total_consultas'] 
                if estadisticas['total_consultas'] > 0 else 0
            )
        }
    }, f, indent=2)
    
    print(f"ğŸ“ˆ MÃ©tricas por ID guardadas en '{archivo_metricas}'")
          
def mostrar_resumen(estadisticas, metricas_ids):
    """Muestra un resumen completo de las estadÃ­sticas"""
    print("\n" + "="*50)
    print("ğŸ“Š RESUMEN FINAL DE ESTADÃSTICAS".center(50))
    print("="*50)
    
    print(f"\nâ± DuraciÃ³n configurada: {estadisticas['config']['duracion_minutos']} minutos")
    print(f"ğŸ†” IDs mÃ­nimos requeridos: {estadisticas['config']['min_ids']}")
    print(f"ğŸ”¢ Total consultas: {estadisticas['total_consultas']}")
    
    if estadisticas['total_consultas'] > 0:
        print(f"\nğŸ’¾ Cache hits: {estadisticas['cache_hits']} ({estadisticas['cache_hits']/estadisticas['total_consultas']:.2%})")
        print(f"âŒ Cache misses: {estadisticas['cache_misses']} ({estadisticas['cache_misses']/estadisticas['total_consultas']:.2%})")
    
    print(f"\nğŸ” IDs Ãºnicos consultados: {len(metricas_ids['conteo_por_id'])}")
    if metricas_ids['conteo_por_id']:
        id_mas, count_mas = max(metricas_ids['conteo_por_id'].items(), key=lambda x: x[1])
        id_menos, count_menos = min(metricas_ids['conteo_por_id'].items(), key=lambda x: x[1])
        print(f"\nğŸ† ID mÃ¡s consultado: {id_mas} (veces: {count_mas})")
        print(f"ğŸ”» ID menos consultado: {id_menos} (veces: {count_menos})")
        print(f"ğŸ“Š Promedio consultas/ID: {estadisticas['total_consultas']/len(metricas_ids['conteo_por_id']):.2f}")

def generar_trafico(duracion_minutos=DURACION_DEFAULT):
    """Ejecuta el generador de trÃ¡fico con el tiempo especificado"""
    limpiar_archivos_anteriores()
    
    # Inicializar estructuras de datos
    estadisticas = {
        'total_consultas': 0,
        'cache_hits': 0,
        'cache_misses': 0,
        'config': {
            'duracion_minutos': duracion_minutos,
            'min_ids': MIN_IDS,
            'cache_url': CACHE_URL,
            'almacenamiento_url': ALMACENAMIENTO_URL
        }
    }
    
    metricas_ids = {
        'conteo_por_id': defaultdict(int),
        'fuentes_por_id': defaultdict(lambda: {'CACHE': 0, 'BACKEND': 0}),
        'timestamp_primer_uso': {},
        'timestamp_ultimo_uso': {}
    }
    
    # Configurar tiempo de ejecuciÃ³n
    hora_fin = datetime.now() + timedelta(minutes=duracion_minutos) if duracion_minutos > 0 else None
    sample_ids = esperar_ids_suficientes()
    
    print(f"\nğŸš€ Iniciando generador ({duracion_minutos} min) | IDs disponibles: {len(sample_ids)}")
    print(f"â° Inicio: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    if hora_fin:
        print(f"â³ Fin estimado: {hora_fin.strftime('%Y-%m-%d %H:%M:%S')}")
    
    try:
        while not hora_fin or datetime.now() < hora_fin:
            id_consulta = random.choice(sample_ids)
            timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            
            try:
                # Consultar al servicio de cache
                response = requests.get(f"{CACHE_URL}/{id_consulta}", timeout=3)
                respuesta = response.json()
                
                # Determinar fuente y actualizar estadÃ­sticas
                fuente = respuesta.get('message', '').lower()
                tipo = 'CACHE' if 'cache' in fuente else 'BACKEND'
                estadisticas['total_consultas'] += 1
                estadisticas['cache_hits' if tipo == 'CACHE' else 'cache_misses'] += 1
                
                # Actualizar mÃ©tricas por ID
                metricas_ids['conteo_por_id'][id_consulta] += 1
                metricas_ids['fuentes_por_id'][id_consulta][tipo] += 1
                if id_consulta not in metricas_ids['timestamp_primer_uso']:
                    metricas_ids['timestamp_primer_uso'][id_consulta] = timestamp
                metricas_ids['timestamp_ultimo_uso'][id_consulta] = timestamp
                
                # Mostrar progreso
                if hora_fin:
                    tiempo_restante = (hora_fin - datetime.now()).total_seconds() / 60
                    print(f"[{timestamp}] ID: {id_consulta} | Fuente: {tipo} | Restante: {tiempo_restante:.1f} min")
                else:
                    print(f"[{timestamp}] ID: {id_consulta} | Fuente: {tipo}")
                
                # Reporte periÃ³dico
                if estadisticas['total_consultas'] % 100 == 0:
                    print(f"\nğŸ“ˆ Consultas: {estadisticas['total_consultas']} | "
                          f"Cache: {estadisticas['cache_hits']} ({estadisticas['cache_hits']/estadisticas['total_consultas']:.1%}) | "
                          f"IDs Ãºnicos: {len(metricas_ids['conteo_por_id'])}")
                
            except Exception as e:
                print(f"[{timestamp}] âŒ Error con ID {id_consulta}: {str(e)}")
            
            time.sleep(generar_intervalo())
            
    except KeyboardInterrupt:
        print("\nğŸ›‘ DetenciÃ³n manual solicitada")
    finally:
        guardar_metricas(estadisticas, metricas_ids)
        mostrar_resumen(estadisticas, metricas_ids)

if __name__ == "__main__":
    args = parse_args()
    generar_trafico(duracion_minutos=args.duracion)