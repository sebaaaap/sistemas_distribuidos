version: '3.8'

services:
  # mongodb:
  #   image: mongo:latest
  #   ports:
  #     - "27017:27017"
  #   volumes:
  #     - mongodb_data:/data/db

  redis:
    image: redis:latest                  # descomentar y comentar la otra para cambiar la politica:
    command: redis-server --maxmemory 256mb --maxmemory-policy allkeys-lru # allkeys-lfu
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    
  # almacenamiento:
  #   build: ./almacenamiento
  #   volumes:
  #     - ./almacenamiento/app:/app
  #   ports:
  #     - "8000:8000"
  #   depends_on:
  #     - mongodb
    
  almacenamiento:
    build: ./almacenamiento
    ports:
      - "8000:8000"
    environment:
      - MONGO_URI=mongodb+srv://${MONGO_USER}:${MONGO_PASSWORD}@${MONGO_CLUSTER}/${MONGO_DB}?retryWrites=true&w=majority&tls=true&authSource=admin
      - MONGO_USER=${MONGO_USER}
      - MONGO_PASSWORD=${MONGO_PASSWORD}
      - MONGO_CLUSTER=${MONGO_CLUSTER}
      - MONGO_DB=${MONGO_DB}
      - MONGO_COLLECTION=${MONGO_COLLECTION}
      
  cache:
    build: ./cache
    ports:
      - "8001:8001"
    depends_on:
      - redis
      - almacenamiento
  
  generador:
    build:
      context: ./generador_trafico
    environment:
      - PYTHONUNBUFFERED=1
      - MIN_IDS=2
      - CACHE_URL=http://cache:8001/eventos
      - ALMACENAMIENTO_URL=http://almacenamiento:8000/eventos/getall_ids
    volumes:
      - ./generador_trafico/app:/app  # Mapeo consistente
    # restart: unless-stopped
    depends_on:
      - almacenamiento
      - cache
    command: >
      sh -c "python main.py --duracion 1" 

  scraper:
   build:
    context: ./scraper
   environment:  
    - URL_MONGODB=http://almacenamiento:8000/eventos
    - MAX_EVENTOS=10 
   depends_on:
    - almacenamiento
    


volumes:
  mongodb_data:
  redis_data: